name: Crawl and Save Data

on:
  workflow_dispatch:  # 수동으로 실행 가능

jobs:
  crawl:
    runs-on: ubuntu-20.04  # 실행 환경
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3  # 리포지토리 코드 가져오기
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'  # 파이썬 버전 설정
      - name: Install dependencies
        run: |
          pip install cloudscraper beautifulsoup4  # 필요한 라이브러리 설치
      - name: Run crawler
        run: python crawl_and_save.py  # 크롤링 스크립트 실행
      - name: Upload artifact
        uses: actions/upload-artifact@v4  # 생성된 파일 업로드
        with:
          name: data-files
          path: data_*.json  # JSON 파일만 업로드
